{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Category Label from Item Name and its Description\n",
    "\n",
    "** Steps: **\n",
    "1. Load dataset and combine name and description into single full text feature\n",
    "2. Convert text feature into numeric feature using label encoder for item category and TfIdf Vectorizer for name and description\n",
    "3. Train a multiclass logistic regression model to establish a baseline performance for the training set\n",
    "4. Train a neural network and compare performance of neural network with simple logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# core data analytics library\n",
    "from IPython.display import display_html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "# machine learning/feature extraction and related library\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"seaborn-muted\")\n",
    "\n",
    "# Some basic configuration\n",
    "train_fraction = 0.8\n",
    "test_fraction = 1 - train_fraction\n",
    "max_features = 10000\n",
    "sample_frac = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"nlp-dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628384, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1008537883</td>\n",
       "      <td>1009127328</td>\n",
       "      <td>1008982705</td>\n",
       "      <td>1006975280</td>\n",
       "      <td>1008950745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>2010 Audi A3</td>\n",
       "      <td>1 tb internal harddrives</td>\n",
       "      <td>3× Mercedes benz Actros 26:40 for sale</td>\n",
       "      <td>Samsung S7 Edge (Rose Pink)</td>\n",
       "      <td>2TB Desktop Hardrive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>A white in colour audi a3 tfsi in good conditi...</td>\n",
       "      <td>Internal harddrives for sale 1tb 3.5 inch for ...</td>\n",
       "      <td>Make     Mercedes benz Actros 26:40\\nModel    ...</td>\n",
       "      <td>Selling my Samsung S7 Edge Rose Pink colour ve...</td>\n",
       "      <td>2TB Desktop Hardrive for a bargain \\n\\nCall or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Cars &amp; Bakkies</td>\n",
       "      <td>Computer Hardware &amp; Accessories</td>\n",
       "      <td>Trucks &amp; Commercial Vehicles</td>\n",
       "      <td>Cell Phones</td>\n",
       "      <td>Computer Hardware &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0  \\\n",
       "id                                                  1008537883   \n",
       "title                                             2010 Audi A3   \n",
       "description  A white in colour audi a3 tfsi in good conditi...   \n",
       "category                                        Cars & Bakkies   \n",
       "\n",
       "                                                             1  \\\n",
       "id                                                  1009127328   \n",
       "title                                 1 tb internal harddrives   \n",
       "description  Internal harddrives for sale 1tb 3.5 inch for ...   \n",
       "category                       Computer Hardware & Accessories   \n",
       "\n",
       "                                                             2  \\\n",
       "id                                                  1008982705   \n",
       "title                   3× Mercedes benz Actros 26:40 for sale   \n",
       "description  Make     Mercedes benz Actros 26:40\\nModel    ...   \n",
       "category                          Trucks & Commercial Vehicles   \n",
       "\n",
       "                                                             3  \\\n",
       "id                                                  1006975280   \n",
       "title                              Samsung S7 Edge (Rose Pink)   \n",
       "description  Selling my Samsung S7 Edge Rose Pink colour ve...   \n",
       "category                                           Cell Phones   \n",
       "\n",
       "                                                             4  \n",
       "id                                                  1008950745  \n",
       "title                                     2TB Desktop Hardrive  \n",
       "description  2TB Desktop Hardrive for a bargain \\n\\nCall or...  \n",
       "category                       Computer Hardware & Accessories  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View/inspect few rows in data\n",
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cars & Bakkies', 'Computer Hardware & Accessories',\n",
       "       'Trucks & Commercial Vehicles', 'Cell Phones',\n",
       "       'Businesses for Sale', 'Furniture & Decor', 'Tools & DIY',\n",
       "       'Houses & Flats for rent', 'Art, Collectibles & Rare Items',\n",
       "       'Car Parts & Accessories', 'Land', 'Clothing & Shoes',\n",
       "       'Rooms for rent & Shared', 'Gym & Fitness', 'TV, Audio & Visual',\n",
       "       'Prams, Cots & Equipment', 'iPads & Tablets',\n",
       "       'Feeds, Supplements & Seeds', 'Gaming & Consoles',\n",
       "       'Musical Instruments', 'Homeware & Appliances',\n",
       "       'Toys, Games & Remote Control', 'Motorcycles & Scooters',\n",
       "       'Dogs & Cats', 'Construction & Home Improvement',\n",
       "       'Outdoor & Sports Equipment', 'Business & Industrial Equipment',\n",
       "       'CVs & Resumes', 'Health, Beauty & Cosmetics',\n",
       "       'Jewellery & Accessories', 'Computers & Laptops',\n",
       "       'Boats & Aviation', 'Garden & Braai',\n",
       "       'Farming Equipment & Vehicles', 'Other Services', 'Bicycles',\n",
       "       'Community Announcements', 'Office Furniture & Equipment',\n",
       "       'Cameras', 'Other pets', 'Books, CDs & DVDs',\n",
       "       \"Toddler's Clothing & Accessories\", 'Shop & Catering Equipment',\n",
       "       'Electronic Installations & Repairs', 'Pet Care & Accessories',\n",
       "       'Job Opportunities', 'Houses & Flats for sale', 'Vacation Rentals',\n",
       "       'Caravans & Trailers', 'Offices, Shops & Commercial Space',\n",
       "       'Inventory & Stock', 'Transport', 'Livestock', 'Event Services',\n",
       "       'Babysitters, Domestic Help & Cleaning'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see all unique categories in data\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cars & Bakkies                           164468\n",
       "Cell Phones                               50316\n",
       "Furniture & Decor                         45247\n",
       "Car Parts & Accessories                   43378\n",
       "Homeware & Appliances                     29019\n",
       "Motorcycles & Scooters                    24225\n",
       "Gaming & Consoles                         20988\n",
       "TV, Audio & Visual                        20688\n",
       "Computers & Laptops                       18207\n",
       "Outdoor & Sports Equipment                16991\n",
       "Tools & DIY                               14611\n",
       "Houses & Flats for rent                   12324\n",
       "Computer Hardware & Accessories           10634\n",
       "Prams, Cots & Equipment                   10009\n",
       "Dogs & Cats                                7643\n",
       "Clothing & Shoes                           7456\n",
       "Art, Collectibles & Rare Items             7263\n",
       "Trucks & Commercial Vehicles               6963\n",
       "Garden & Braai                             6354\n",
       "Bicycles                                   6037\n",
       "Business & Industrial Equipment            5933\n",
       "iPads & Tablets                            5919\n",
       "Jewellery & Accessories                    5686\n",
       "Caravans & Trailers                        5678\n",
       "Construction & Home Improvement            5666\n",
       "Rooms for rent & Shared                    5528\n",
       "Toys, Games & Remote Control               5360\n",
       "Gym & Fitness                              5233\n",
       "Cameras                                    4719\n",
       "Farming Equipment & Vehicles               4363\n",
       "Health, Beauty & Cosmetics                 4191\n",
       "Musical Instruments                        3998\n",
       "Office Furniture & Equipment               3992\n",
       "Books, CDs & DVDs                          3266\n",
       "CVs & Resumes                              3062\n",
       "Houses & Flats for sale                    2870\n",
       "Pet Care & Accessories                     2795\n",
       "Other Services                             2771\n",
       "Boats & Aviation                           2736\n",
       "Transport                                  2551\n",
       "Community Announcements                    2180\n",
       "Other pets                                 2136\n",
       "Shop & Catering Equipment                  2115\n",
       "Toddler's Clothing & Accessories           2041\n",
       "Livestock                                  1856\n",
       "Inventory & Stock                          1779\n",
       "Electronic Installations & Repairs         1071\n",
       "Event Services                             1068\n",
       "Vacation Rentals                           1068\n",
       "Businesses for Sale                         969\n",
       "Job Opportunities                           932\n",
       "Offices, Shops & Commercial Space           758\n",
       "Land                                        553\n",
       "Feeds, Supplements & Seeds                  371\n",
       "Babysitters, Domestic Help & Cleaning       349\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency of each category\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test set data\n",
    "test = pd.read_csv(\"nlp-dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008387829</td>\n",
       "      <td>Massage Chair</td>\n",
       "      <td>Electronic Massage Chair. Very good condition....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007542388</td>\n",
       "      <td>Acer Aspire AX3910 PC desktop with windows 10 Pro</td>\n",
       "      <td>This is the best PC for any student its in gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009234002</td>\n",
       "      <td>Beach buggy</td>\n",
       "      <td>Hy is nie voledig nie en het nie papiere nie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007888574</td>\n",
       "      <td>Rest Assured Double mattress for sale great co...</td>\n",
       "      <td>Very great condition firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007436437</td>\n",
       "      <td>2008 Volkswagen Polo 1.9 TDi Highline</td>\n",
       "      <td>Factory Features\\r\\n\\r\\n- ABS\\r\\n- Airbags\\r\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  1008387829                                      Massage Chair   \n",
       "1  1007542388  Acer Aspire AX3910 PC desktop with windows 10 Pro   \n",
       "2  1009234002                                        Beach buggy   \n",
       "3  1007888574  Rest Assured Double mattress for sale great co...   \n",
       "4  1007436437              2008 Volkswagen Polo 1.9 TDi Highline   \n",
       "\n",
       "                                         description  \n",
       "0  Electronic Massage Chair. Very good condition....  \n",
       "1  This is the best PC for any student its in gre...  \n",
       "2       Hy is nie voledig nie en het nie papiere nie  \n",
       "3                          Very great condition firm  \n",
       "4  Factory Features\\r\\n\\r\\n- ABS\\r\\n- Airbags\\r\\n...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect few rows of test set data\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preparing Title and Description **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "title           0\n",
       "description    14\n",
       "category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if training set have null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace null with empty string\n",
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# derive full text feature by combining title and descrition of each item\n",
    "df[\"full_text\"] = df.title + \" \" + df.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preparing/Encoding Category **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(df.category)\n",
    "df[\"category_id\"] = encoder.transform(df.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Partition Data in Two Set: Training and Test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = df\n",
    "df = df.sample(frac=sample_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=train_fraction)\n",
    "test_df = df[~df.index.isin(train_df.index)].reset_index(drop=True)\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Process Text Feature **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_column = \"full_text\"\n",
    "vec = TfidfVectorizer(max_features=max_features, ngram_range=(1, 3), analyzer=\"word\", \n",
    "                      stop_words=\"english\", token_pattern=r\"(?u)\\b\\w+\\b\").fit(train_df[text_column])\n",
    "assert len(vec.vocabulary_) == max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = vec.transform(train_df.loc[:,text_column])\n",
    "#pd.DataFrame(vec.transform(train_df.loc[:,text_column]).todense(), columns=vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = vec.transform(test_df.loc[:,text_column])\n",
    "# pd.DataFrame(vec.transform(test_df.loc[:,text_column]).todense(), columns=vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to find model score\n",
    "def model_score(actual, predicted):\n",
    "    return 1.0 * np.sum((predicted == actual)) / actual.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder().fit(df.category_id.values.reshape(-1, 1))\n",
    "def one_hot_encoding(df, category=55):\n",
    "    return np.asarray(oh_encoder.transform(df.category_id.values.reshape([-1, 1])).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Multiclass Logistic Regression **\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(penalty='l2', multi_class='multinomial', solver='lbfgs', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.3min finished\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier.fit(train_dataset, train_df.category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = classifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389601916022821"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(pred, test_df.category_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bag of Word Model **\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# losses: binary_crossentropy, categorical_crossentropy\n",
    "def get_bow_model(input_shape, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(768, input_shape=input_shape))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=\"Adadelta\",\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparseToDenseSequence(Sequence):\n",
    "    def __init__(self, X, y=None, batch_size=256, train=False):\n",
    "        super(SparseToDenseSequence, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.train = train\n",
    "        self.batches = int((X.shape[0] + batch_size - 1) / batch_size)\n",
    "        self.indices = np.arange(self.X.shape[0])\n",
    "        if self.train:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def get_item_y(self, index):\n",
    "        selected = self.indices[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        return (self.X[selected,:].todense(), self.y[selected,:])\n",
    "    \n",
    "    def get_item(self, index):\n",
    "        selected = self.indices[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        return self.X[selected,:].todense()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.y is not None:\n",
    "            return self.get_item_y(index)\n",
    "        else:\n",
    "            return self.get_item(index)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batches\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.train:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "884/884 [==============================] - 294s - loss: 1.9439 - acc: 0.6034 - val_loss: 1.0015 - val_acc: 0.7799\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 293s - loss: 0.8265 - acc: 0.8022 - val_loss: 0.6667 - val_acc: 0.8318\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 291s - loss: 0.6551 - acc: 0.8331 - val_loss: 0.6073 - val_acc: 0.8421\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 287s - loss: 0.5942 - acc: 0.8433 - val_loss: 0.5838 - val_acc: 0.8440\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 289s - loss: 0.5552 - acc: 0.8515 - val_loss: 0.5697 - val_acc: 0.8474\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 308s - loss: 0.5226 - acc: 0.8583 - val_loss: 0.5575 - val_acc: 0.8487\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 293s - loss: 0.4946 - acc: 0.8644 - val_loss: 0.5527 - val_acc: 0.8497\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 300s - loss: 0.4679 - acc: 0.8704 - val_loss: 0.5501 - val_acc: 0.8512\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 290s - loss: 0.4429 - acc: 0.8764 - val_loss: 0.5467 - val_acc: 0.8516\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 293s - loss: 0.4177 - acc: 0.8829 - val_loss: 0.5451 - val_acc: 0.8513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152d1e790>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = one_hot_encoding(train_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataset, label, test_size=0.1, random_state=0)\n",
    "batch_size = 512\n",
    "model = get_bow_model((X_train.shape[1],), 55)\n",
    "train_generator = SparseToDenseSequence(X=X_train, y=y_train, batch_size=batch_size, train=True)\n",
    "validation_generator = SparseToDenseSequence(X=X_test, y=y_test, batch_size=batch_size)\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 33s    \n"
     ]
    }
   ],
   "source": [
    "predict_generator = SparseToDenseSequence(test_dataset, y=None, batch_size=batch_size)\n",
    "pred = model.predict_generator(\n",
    "    generator=predict_generator,\n",
    "    steps=len(predict_generator),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850068031541173"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pred.argmax(axis=1)\n",
    "model_score(test_df.category_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = test\n",
    "test_df.fillna(\"\", inplace=True)\n",
    "test_df[\"full_text\"] = test_df.title + \" \" + test_df.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/246 [===========>..................] - ETA: 19s"
     ]
    }
   ],
   "source": [
    "test_dataset = vec.transform(test_df.loc[:,text_column])\n",
    "predict_generator = SparseToDenseSequence(test_dataset, y=None, batch_size=batch_size)\n",
    "pred = model.predict_generator(\n",
    "    generator=predict_generator,\n",
    "    steps=len(predict_generator),\n",
    "    verbose=1\n",
    ")\n",
    "prediction = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df[\"category_id\"] = prediction\n",
    "test_df[\"category\"] = encoder.inverse_transform(prediction)\n",
    "test_df = test_df[[\"id\", \"category\"]]\n",
    "test_df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
